<!DOCTYPE html>
<html>
    <head>
  <meta charset="utf-8">
  <meta name="description" content="VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting">
  <meta name="keywords" content="VITA-E, VLA, Embodied Interaction, Embodied AI, Vision-Language-Action">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/vita-e-logo.png">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

        <style>
            .pill {
                display: inline-block;
                background: #e6f6fd;
                color: #0369a1;
                border: 1px solid #bae6fd;
                border-radius: 999px;
      padding: 4px 12px;
      margin: 4px;
                font-size: 14px;
      font-weight: 500;
            }
            .kpi {
                display: flex;
                gap: 14px;
                flex-wrap: wrap;
                justify-content: center;
      margin-top: 1rem;
            }
            .kpi .item {
      border: 1px solid #e2e8f0;
                border-radius: 10px;
      padding: 12px 16px;
      background: #f8fafc;
      font-size: 14px;
    }
            .token-table {
                width: 100%;
                border-collapse: collapse;
      margin-top: 1rem;
            }
            .token-table th,
            .token-table td {
      border: 1px solid #e2e8f0;
      padding: 12px;
                text-align: left;
                vertical-align: top;
            }
            .token-table th {
      background: #f8fafc;
      font-weight: 600;
    }
    .token-table code {
      background: #f1f5f9;
      padding: 2px 6px;
      border-radius: 4px;
      font-family: 'Courier New', monospace;
      font-size: 0.9em;
            }
        </style>

    </head>
    <body>

<!-- ‰øÆÂ§çÂêéÁöÑ Navbar ‰ª£Á†Å -->
<nav class="navbar" role="navigation" aria-label="main navigation" style="background-color: white; box-shadow: none; border-bottom: none;">
        <div class="container">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarMenu">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>

    <div id="navbarMenu" class="navbar-menu">
      <div class="navbar-start" style="margin-left: auto; margin-right: auto;">
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            <span style="margin-right: 5px;">üî•</span>
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://ltbai.github.io/VITA-VLA" target="_blank">
              <strong>VITA-VLA</strong>
            </a>
            <a class="navbar-item" href="https://github.com/VITA-MLLM/VITA" target="_blank">
              <strong>VITA-1.5</strong>
            </a>
            <a class="navbar-item" href="https://github.com/VITA-MLLM/Long-VITA" target="_blank">
              <strong>Long-VITA</strong>
            </a>
            <a class="navbar-item" href="https://github.com/VITA-MLLM/VITA-Audio" target="_blank">
              <strong>VITA-Audio</strong>
            </a>
            <a class="navbar-item" href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models" target="_blank">
              <strong>MME</strong>
            </a>
            <a class="navbar-item" href="https://github.com/MME-Benchmarks/Video-MME" target="_blank">
              <strong>Video-MME</strong>
            </a>
            <a class="navbar-item" href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models" target="_blank">
              <strong>Awesome-MLLM</strong>
            </a>
          </div>
        </div>
      </div>
                </div>
                </div>
</nav>

<!-- Â¶ÇÊûúÈúÄË¶ÅËá™ÂÆö‰πâÊ†∑ÂºèÔºåÊ∑ªÂä†Ëøô‰∏™CSS -->
<style>
  /* Á°Æ‰øùÂØºËà™Ê†èÂßãÁªàÂèØËßÅ - ÁôΩËâ≤ËÉåÊôØÔºåÊó†ËæπÊ°Ü */
  .navbar {
    background-color: white;
    min-height: 3.25rem;
    box-shadow: none;
    border: none;
  }
  
  /* Á°Æ‰øù More Research Â±Ö‰∏≠ÊòæÁ§∫ */
  .navbar-start {
    display: flex;
    justify-content: center;
    flex-grow: 1;
  }
  
  /* ‰∏ãÊãâËèúÂçïÊ†∑Âºè - Êó†ËæπÊ°Ü */
  .navbar-dropdown {
    border-top: none;
    background-color: white;
    box-shadow: 0 8px 8px rgba(10, 10, 10, 0.1);
  }
  
  .navbar-item:hover {
    background-color: #fafafa;
  }
  
  .navbar-link:hover {
    background-color: #fafafa;
  }
  
  /* ÁßªÂä®Á´ØÂìçÂ∫îÂºè */
  @media screen and (max-width: 1023px) {
    .navbar-menu {
      background-color: white;
      box-shadow: none;
    }
  }
  </style>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://github.com/lxysl">Xiaoyu Liu</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://github.com/BradyFU">Chaoyou Fu</a><sup>1,‚Ä†</sup>,</span>
            <span class="author-block"><a href="https://openreview.net/profile?id=~Chi_Yan2">Chi Yan</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://openreview.net/profile?id=~Chu_Wu1">Chu Wu</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://openreview.net/profile?id=~Haihan_Gao1">Haihan Gao</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://openreview.net/profile?id=~YiFan_Zhang8">Yi-Fan Zhang</a><sup>3</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://github.com/ltBai">Shaoqi Dong</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://openreview.net/profile?id=~Cheng_Qian8">Cheng Qian</a><sup>4</sup>,</span>
            <span class="author-block"><a href="https://openreview.net/profile?id=~Bin_Luo15">Bin Luo</a><sup>4</sup>,</span>
            <span class="author-block"><a href="https://openreview.net/profile?id=~Yangxiuyong1">Xiuyong Yang</a><sup>4</sup>,</span>
            <span class="author-block"><a href="https://openreview.net/profile?id=~guanwuli1">Guanwu Li</a><sup>4</sup>,</span>
            <span class="author-block"><a href="https://openreview.net/profile?id=~Yusheng_Cai1">Yusheng Cai</a><sup>4</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://scholar.google.com/citations?user=29teR74AAAAJ&hl=zh-CN&oi=ao">Yunhang Shen</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?hl=zh-CN&user=v4AK2MQAAAAJ">Deqiang Jiang</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?hl=zh-CN&user=LV8ejn8AAAAJ">Haoyu Cao</a><sup>2,‚Ä°</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?hl=zh-CN&user=IUtix9IAAAAJ">Xing Sun</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?hl=zh-CN&user=fIXA_SsAAAAJ">Caifeng Shan</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?hl=zh-CN&user=ayrg9AUAAAAJ">Ran He</a><sup>3</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Nanjing University,</span>
            <span class="author-block"><sup>2</sup>Tencent Youtu Lab,</span>
            <span class="author-block"><sup>3</sup>CASIA,</span>
            <span class="author-block"><sup>4</sup>Fourier Intelligence Inc.</span>
          </div>

          <div class="is-size-6 publication-authors" style="margin-top: 0.5rem;">
            <span class="author-block"><sup>‚Ä†</sup>Corresponding author,</span>
            <span class="author-block"><sup>‚Ä°</sup>Project leader</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- Arxiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.21817"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Tencent/VITA/tree/VITA-E"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Hugging Face Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/VITA-MLLM/VITA-E"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ü§ó
                  </span>
                  <span>Model</span>
                  </a>
              </span>
            </div>
          </div>

          <!-- Badges -->
          <!-- <div style="margin-top: 1.5rem;">
            <span class="pill">Real-time</span>
            <span class="pill">Interruptible</span>
            <span class="pill">Concurrency</span>
            <span class="pill">Model-as-Controller</span>
            <span class="pill">VLM + Diffusion Action Expert</span>
          </div> -->
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Demo Video -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" controls loop playsinline height="100%">
        <source src="./static/videos/VITA-E.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered" style="margin-top: 1rem; font-size: 1.5rem;">
        <b>VITA-E</b> enables concurrent, and nearly real-time interruptible human-robot interaction through a dual-model framework.
      </h2>
    </div>
  </div>
</section>


<!-- Abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Current Vision-Language-Action (VLA) models are often constrained by a rigid, static interaction paradigm, which lacks the ability to see, hear, speak, and act concurrently as well as handle real-time user interruptions dynamically. This hinders seamless human-robot collaboration, resulting in an inflexible and unresponsive user experience. To address these limitations, we introduce <b>VITA-E</b>, a novel human-robot interaction framework designed for both behavioral concurrency and nearly real-time interruption. The core of our approach is a dual-model architecture where two parallel VLA instances operate as an "Active Model" and a "Standby Model", allowing the robot to observe its environment, listen to user speech, provide verbal responses, and execute actions, all concurrently and interruptibly, mimicking human-like multitasking capabilities. We further propose a <b>"model-as-controller"</b> paradigm, where we fine-tune the VLM to generate special tokens that serve as direct system-level commands, coupling the model's reasoning with the system's behavior. Experiments conducted on a physical humanoid robot demonstrate that VITA-E can reliably handle complex interactive scenarios. Our framework is compatible with various dual-system VLA models, achieving an extremely high success rate on emergency stops and speech interruptions while also successfully performing concurrent speech and action. This represents a significant step towards more natural and capable robotic assistants. Our homepage is <a href="https://lxysl.github.io/VITA-E/" target="_blank">https://lxysl.github.io/VITA-E/</a>.
                        </p>
                    </div>
                </div>
                    </div>
                </div>
            </section>


<!-- System Architecture -->
<section class="hero teaser">
  <div class="columns is-centered">
    <div class="column is-four-fifths has-text-centered">
      <h2 class="title is-3 mb-5">System Architecture</h2>
      <div style="width:85%; margin:0 auto;">
        <img src="static/images/architecture.png" style="width:100%; height:auto; margin-bottom:1rem;">
        <p class="has-text-justified is-size-6" style="margin-top:1rem;">
          <b>Architecture:</b> VITA-E follows two principles: <b>VLM-as-controller</b> and a <b>dual-model core</b>. The VLM (System-2) handles high-level understanding, while a diffusion-based action expert (System-1) handles low-level motor control. The first token controls the system state: <code>[RES]</code> for voice-only response, <code>[ACT]</code> to enter action mode with the instruction after <code>[INST]</code> as the semantic goal, <code>[HALT]</code> for immediate stop, and <code>[END]</code> for task completion. The Listening model can preempt or run concurrently at any time.
        </p>
      </div>
    </div>
                </div>
</section>


<!-- Interaction Modes -->
<section class="hero teaser">
  <div class="columns is-centered">
    <div class="column is-four-fifths has-text-centered">
      <h2 class="title is-3 mb-5">Interaction Modes</h2>
      <div style="width:85%; margin:0 auto;">
        <img src="static/images/logic.png" style="width:100%; height:auto; margin-bottom:1rem;">
        <p class="has-text-justified is-size-6" style="margin-top:1rem;">
          <b>Interaction modes:</b> speech interruption, concurrent speech+action, task switching, and emergency stop.
        </p>
                </div>
      <!-- KPIs -->
      <div class="kpi">
                    <div class="item"><b>Speech interruption</b>: 100%</div>
                    <div class="item"><b>Emergency stop</b>: 100%</div>
                    <div class="item"><b>Task switching</b>: 93.3%</div>
        <div class="item"><b>Avg. voice response latency</b>: 2.26s</div>
      </div>
                    </div>
                </div>
            </section>


<!-- Key Features -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Key Features</h2>
        <div style="margin-top: 1rem;">
                    <span class="pill">Dual-model interaction core</span>
                    <span class="pill">Special control tokens</span>
                    <span class="pill">Speech-action concurrency</span>
                    <span class="pill">Unified interruption mechanism</span>
                    <span class="pill">Compatible with mainstream VLAs</span>
        </div>

        <!-- Special Tokens Table -->
        <h3 class="title is-4" style="margin-top: 2rem;">Special Control Tokens</h3>
        <div class="content">
                    <table class="token-table">
                        <thead>
                            <tr>
                <th style="width: 100px">Token</th>
                <th style="width: 40%">Description</th>
                                <th>Example Model Output</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><code>[RES]</code></td>
                <td>Signals a voice-only response. Generated as the first token for conversational replies.</td>
                <td><code>[RES]</code> I see an apple on the table.</td>
                            </tr>
                            <tr>
                                <td><code>[ACT]</code></td>
                <td>Signals that the response includes a physical action. Generated as the first token to enter action mode.</td>
                <td><code>[ACT]</code> Okay, I will put the toy in the box. <code>[INST]</code> Pick up toy and place in box.</td>
                            </tr>
                            <tr>
                                <td><code>[INST]</code></td>
                <td>Delimits the spoken part of an action response from the internal action instruction that follows.</td>
                <td>Used after <code>[ACT]</code> to separate speech from the action instruction.</td>
                            </tr>
                            <tr>
                                <td><code>[HALT]</code></td>
                <td>Commands an immediate stop of the current action. Generated as the first token for emergency stops.</td>
                <td><code>[HALT]</code> Stopping immediately.</td>
                            </tr>
                            <tr>
                                <td><code>[END]</code></td>
                <td>Signals that a multi-step action sequence has been successfully completed.</td>
                <td><code>[END]</code> The action is finished.</td>
                            </tr>
                        </tbody>
                    </table>
        </div>
      </div>
    </div>
                </div>
            </section>


<!-- Experiments -->
<section class="hero teaser">
  <div class="columns is-centered">
    <div class="column is-four-fifths has-text-centered">
      <h2 class="title is-3 mb-5">Experiments</h2>
      <div style="width:80%; margin:0 auto;">
        <p class="has-text-justified is-size-6" style="margin-bottom:1.5rem;">
          We evaluate on the Fourier GR2 humanoid platform and the LIBERO benchmark. VITA-E is competitive on fundamental pick-and-place tasks and reliably delivers concurrency, interruption, and emergency stop in interactive scenarios.
        </p>
        
        <img src="static/images/results.png" style="width:100%; height:auto; margin-bottom:1rem;">
        <p class="has-text-justified is-size-6" style="margin-top:1rem; margin-bottom:2.5rem;">
          <b>Comparison on two manipulation tasks:</b> success rates over 30 trials.
        </p>

        <img src="static/images/libero.png" style="width:100%; height:auto; margin-bottom:1rem;">
        <p class="has-text-justified is-size-6" style="margin-top:1rem;">
          <b>LIBERO benchmark:</b> competitive performance with frozen VLM.
        </p>
      </div>
                </div>
                </div>
            </section>


<!-- BibTeX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{liu2025vitae,
  title={VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting},
  author={Xiaoyu Liu, Chaoyou Fu, Chi Yan, Chu Wu, Haihan Gao, Yi-Fan Zhang, Shaoqi Dong, Cheng Qian, Bin Luo, Xiuyong Yang, Guanwu Li, Yusheng Cai, Yunhang Shen, Deqiang Jiang, Haoyu Cao, Xing Sun, Caifeng Shan, Ran He},
  journal={arXiv preprint arXiv:2510.21817},
  year={2025}
}</code></pre>
                </div>
            </section>


            <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            ¬© 2025 VITA Team.
          </p>
          <p>
            This website is built using the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies template</a>, 
            licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

    </body>
</html>
